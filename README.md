# Expressive Interaction Design using Facial Muscles as Controllers
[Expressive Interaction Design Using Facial Muscles as Controllers](https://www.academia.edu/119107491/Expressive_Interaction_Design_Using_Facial_Muscles_as_Controllers)

**A system for controlling virtual avatars through facial muscle movements.**

## Problem Statement
Facial muscle weakness can significantly impact social interaction and quality of life. Existing rehabilitation methods often have limitations.

## Methodology
Developed a system using EMG sensors to capture facial muscle activity. This data is processed and used to control the facial expressions of a virtual avatar in a real-time environment.

## Results
The system successfully demonstrated the ability to map facial muscle movements to avatar expressions. Initial user feedback was positive, indicating potential for rehabilitation and social interaction.

## Technology Stack
* [Unity](https://unity.com/)
* [Arduino](https://www.arduino.cc/)
* EMG sensors & [EMG Filters](https://github.com/oymotion/EMGFilters)
* [Ardity](https://ardity.dwilches.com/)

## License
This project is free to use under [MIT License](https://opensource.org/license/mit). Please refer to the LICENSE file for details.

## Contact
If you have any questions or feedback, feel free to reach out to me:

[GIT](https://github.com/isaacfurieri)

[LinkedIn](https://www.linkedin.com/in/isaac-furieri-19788474/)
